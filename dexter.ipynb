{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7d8b50-cf29-4597-868b-981809aaa7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 14:48:45.935706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-09 14:48:45.935751: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import mo_descriptor as md\n",
    "import nn_frame as nn\n",
    "import numpy as np\n",
    "import subprocess\n",
    "subprocess.run('export TF_INTRA_OP_PARALLELISM_THREADS=12', shell=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc5bade-1f3f-42a8-b098-99f4e535cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prepare data_set\n",
    "1. make mo_pair descriptor\n",
    "'''\n",
    "# x_shift = np.arange(0, 4.1, 0.1)\n",
    "# y_shift = np.arange(0, 4.1, 0.1)\n",
    "# z_shift = np.zeros(x_shift.shape)\n",
    "# # the original mo, e.g. homo\n",
    "# homo = md.MO_descriptor('data/homo-s0.cube').make()\n",
    "# lumo = md.MO_descriptor('data/lumo-s0.cube').make()\n",
    "\n",
    "# # for the original pair of one mo and itself\n",
    "# homo_pair = md.MO_pair_descriptor(homo, homo).make()\n",
    "# lumo_pair = md.MO_pair_descriptor(lumo, lumo).make()\n",
    "\n",
    "# homo_pairs = np.zeros((len(x_shift)*len(y_shift),) + homo_pair.shape)\n",
    "# lumo_pairs = np.zeros((len(x_shift)*len(y_shift),) + lumo_pair.shape)\n",
    "\n",
    "# homo_ = np.zeros(homo.shape)\n",
    "# lumo_ = np.zeros(lumo.shape)\n",
    "\n",
    "# for ii, i in enumerate(x_shift):\n",
    "#     for jj, j in enumerate(y_shift):\n",
    "#         idx = ii * len(y_shift) + jj\n",
    "#         homo_[:,0] = np.add(homo[:,0],0)\n",
    "#         homo_[:,1] = np.add(homo[:,1],i)\n",
    "#         homo_[:,2] = np.add(homo[:,2],j)\n",
    "#         homo_[:,3] = np.add(homo[:,3],0)\n",
    "        \n",
    "#         homo_pair_ = md.MO_pair_descriptor(homo, homo_).make()\n",
    "#         homo_pairs[idx] = homo_pair_\n",
    "        \n",
    "#         lumo_[:,0] = np.add(lumo[:,0],0)\n",
    "#         lumo_[:,1] = np.add(lumo[:,1],i)\n",
    "#         lumo_[:,2] = np.add(lumo[:,2],j)\n",
    "#         lumo_[:,3] = np.add(lumo[:,3],0)\n",
    "        \n",
    "#         lumo_pair_ = md.MO_pair_descriptor(lumo, lumo_).make()\n",
    "#         lumo_pairs[idx] = lumo_pair_\n",
    "\n",
    "# np.save('homo_homo_pair.npy', homo_pairs)\n",
    "# np.save('lumo_lumo_pair.npy', lumo_pairs)\n",
    "homo_pairs = np.load('homo_homo_pair.npy')\n",
    "lumo_pairs = np.load('lumo_lumo_pair.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c365325-cdde-46dd-8116-e37ac462e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. read coupling\n",
    "'''\n",
    "raw_data = np.loadtxt('data/cdftcoupling.csv', delimiter=',')\n",
    "c_dexter = np.array(raw_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940ac5df-39a3-405f-895c-e0b62ce17c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_pairs = []\n",
    "for ii, i in enumerate(homo_pairs):\n",
    "    mo_pairs.append((homo_pairs[ii],lumo_pairs[ii]))\n",
    "mo_pairs = np.array(mo_pairs)\n",
    "\n",
    "train_mo_pairs = mo_pairs\n",
    "train_c_dexter = -np.log(c_dexter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9470e1-8047-435d-809b-2fe737c2c669",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 14:48:48.494682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-09 14:48:48.494732: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-09 14:48:48.494767: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Bai-Group): /proc/driver/nvidia/version does not exist\n",
      "2022-09-09 14:48:48.495095: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  39.4951172\n",
      "training step:     0\n",
      "loss:  2.07879496\n",
      "training step:  1000\n",
      "loss:  1.26056564\n",
      "training step:  2000\n",
      "loss:  1.00749707\n",
      "training step:  3000\n",
      "loss:  0.905465901\n",
      "training step:  4000\n",
      "loss:  0.722550273\n",
      "training step:  5000\n",
      "loss:  0.562547147\n",
      "training step:  6000\n",
      "loss:  0.469641417\n",
      "training step:  7000\n",
      "loss:  0.341648221\n",
      "training step:  8000\n",
      "loss:  0.281329364\n",
      "training step:  9000\n",
      "loss:  0.228121296\n",
      "training step: 10000\n",
      "loss:  0.171382129\n",
      "training step: 11000\n",
      "loss:  0.145610437\n",
      "training step: 12000\n",
      "loss:  0.128639147\n",
      "training step: 13000\n",
      "loss:  0.113469981\n",
      "training step: 14000\n",
      "loss:  0.101457573\n",
      "training step: 15000\n",
      "loss:  0.0909623\n",
      "training step: 16000\n",
      "loss:  0.0831812844\n",
      "training step: 17000\n",
      "loss:  0.0753862411\n",
      "training step: 18000\n",
      "loss:  0.0676894933\n",
      "training step: 19000\n",
      "loss:  0.0618827268\n",
      "training step: 20000\n",
      "loss:  0.0565434583\n",
      "training step: 21000\n",
      "loss:  0.0546609797\n",
      "training step: 22000\n",
      "loss:  0.0514278859\n",
      "training step: 23000\n",
      "loss:  0.0474363528\n",
      "training step: 24000\n",
      "loss:  0.040261995\n",
      "training step: 25000\n",
      "loss:  0.0386205949\n",
      "training step: 26000\n",
      "loss:  0.0352552794\n",
      "training step: 27000\n",
      "loss:  0.0346012339\n",
      "training step: 28000\n",
      "loss:  0.0306735262\n",
      "training step: 29000\n",
      "loss:  0.0357434\n",
      "training step: 30000\n",
      "loss:  0.0268096961\n",
      "training step: 31000\n",
      "loss:  0.0252438784\n",
      "training step: 32000\n",
      "loss:  0.0260232296\n",
      "training step: 33000\n",
      "loss:  0.0245754123\n",
      "training step: 34000\n",
      "loss:  0.0211005174\n",
      "training step: 35000\n",
      "loss:  0.0208263062\n",
      "training step: 36000\n",
      "loss:  0.0218356252\n",
      "training step: 37000\n",
      "loss:  0.0194979347\n",
      "training step: 38000\n",
      "loss:  0.0200089086\n",
      "training step: 39000\n",
      "loss:  0.0185249373\n",
      "training step: 40000\n",
      "loss:  0.020971695\n",
      "training step: 41000\n",
      "loss:  0.0194881801\n",
      "training step: 42000\n",
      "loss:  0.0190213639\n",
      "training step: 43000\n",
      "loss:  0.0179419443\n",
      "training step: 44000\n",
      "loss:  0.022827547\n",
      "training step: 45000\n",
      "loss:  0.0181781631\n",
      "training step: 46000\n",
      "loss:  0.0188983884\n",
      "training step: 47000\n",
      "loss:  0.0157263391\n",
      "training step: 48000\n",
      "loss:  0.0172903668\n",
      "training step: 49000\n",
      "loss:  0.0143611142\n",
      "training step: 50000\n",
      "loss:  0.0137253152\n",
      "training step: 51000\n",
      "loss:  0.016269872\n",
      "training step: 52000\n",
      "loss:  0.0187456124\n",
      "training step: 53000\n",
      "loss:  0.016063869\n",
      "training step: 54000\n",
      "loss:  0.0119138211\n",
      "training step: 55000\n",
      "loss:  0.0139278295\n",
      "training step: 56000\n",
      "loss:  0.0116090029\n",
      "training step: 57000\n",
      "loss:  0.0257276054\n",
      "training step: 58000\n",
      "loss:  0.0134948334\n",
      "training step: 59000\n",
      "loss:  0.0116120679\n",
      "training step: 60000\n",
      "loss:  0.0144501766\n",
      "training step: 61000\n",
      "loss:  0.0109732896\n",
      "training step: 62000\n",
      "loss:  0.0131203188\n",
      "training step: 63000\n",
      "loss:  0.0101543758\n",
      "training step: 64000\n",
      "loss:  0.0159470271\n",
      "training step: 65000\n",
      "loss:  0.0103892274\n",
      "training step: 66000\n",
      "loss:  0.0099011939\n",
      "training step: 67000\n",
      "loss:  0.0119074751\n",
      "training step: 68000\n",
      "loss:  0.00865190942\n",
      "training step: 69000\n",
      "loss:  0.00995681342\n",
      "training step: 70000\n",
      "loss:  0.00980530586\n",
      "training step: 71000\n",
      "loss:  0.00923860446\n",
      "training step: 72000\n",
      "loss:  0.00951216463\n",
      "training step: 73000\n",
      "loss:  0.0103131291\n",
      "training step: 74000\n",
      "loss:  0.0082141906\n",
      "training step: 75000\n",
      "loss:  0.00824090093\n",
      "training step: 76000\n",
      "loss:  0.00842991751\n",
      "training step: 77000\n",
      "loss:  0.00710566062\n",
      "training step: 78000\n",
      "loss:  0.0136849806\n",
      "training step: 79000\n",
      "loss:  0.00678752596\n",
      "training step: 80000\n",
      "loss:  0.00661010947\n",
      "training step: 81000\n",
      "loss:  0.0064282692\n",
      "training step: 82000\n",
      "loss:  0.0070979204\n",
      "training step: 83000\n",
      "loss:  0.00735349441\n",
      "training step: 84000\n",
      "loss:  0.00682768412\n",
      "training step: 85000\n",
      "loss:  0.00797518622\n",
      "training step: 86000\n",
      "loss:  0.00651294366\n",
      "training step: 87000\n",
      "loss:  0.00615349086\n",
      "training step: 88000\n",
      "loss:  0.00661516655\n",
      "training step: 89000\n",
      "loss:  0.0056854235\n",
      "training step: 90000\n",
      "loss:  0.00652684318\n",
      "training step: 91000\n",
      "loss:  0.00609838869\n",
      "training step: 92000\n",
      "loss:  0.00708030723\n",
      "training step: 93000\n",
      "loss:  0.00693831127\n",
      "training step: 94000\n",
      "loss:  0.00596500374\n",
      "training step: 95000\n",
      "loss:  0.00609661359\n",
      "training step: 96000\n",
      "loss:  0.00509927608\n",
      "training step: 97000\n",
      "loss:  0.00540912105\n",
      "training step: 98000\n",
      "loss:  0.0057079182\n",
      "training step: 99000\n",
      "loss:  0.00585580152\n",
      "training step: 100000\n",
      "loss:  0.0157806445\n",
      "training step: 101000\n",
      "loss:  0.00549917761\n",
      "training step: 102000\n",
      "loss:  0.00614224235\n",
      "training step: 103000\n",
      "loss:  0.00478856405\n",
      "training step: 104000\n",
      "loss:  0.00499025\n",
      "training step: 105000\n",
      "loss:  0.00499186199\n",
      "training step: 106000\n",
      "loss:  0.00449886685\n",
      "training step: 107000\n",
      "loss:  0.0054961578\n",
      "training step: 108000\n",
      "loss:  0.00965290423\n",
      "training step: 109000\n",
      "loss:  0.0066836318\n",
      "training step: 110000\n",
      "loss:  0.00431789877\n",
      "training step: 111000\n",
      "loss:  0.00504787546\n",
      "training step: 112000\n",
      "loss:  0.00432981178\n",
      "training step: 113000\n",
      "loss:  0.00528236665\n",
      "training step: 114000\n",
      "loss:  0.00475874357\n",
      "training step: 115000\n",
      "loss:  0.00420100056\n",
      "training step: 116000\n",
      "loss:  0.00409459183\n",
      "training step: 117000\n",
      "loss:  0.00626987824\n",
      "training step: 118000\n",
      "loss:  0.00395038538\n",
      "training step: 119000\n",
      "loss:  0.00506040966\n",
      "training step: 120000\n",
      "loss:  0.00392803829\n",
      "training step: 121000\n",
      "loss:  0.00576417474\n",
      "training step: 122000\n",
      "loss:  0.00394855114\n",
      "training step: 123000\n",
      "loss:  0.00393624138\n",
      "training step: 124000\n",
      "loss:  0.00385133177\n",
      "training step: 125000\n",
      "loss:  0.00475540664\n",
      "training step: 126000\n",
      "loss:  0.00374467671\n",
      "training step: 127000\n",
      "loss:  0.00353708724\n",
      "training step: 128000\n",
      "loss:  0.00384306093\n",
      "training step: 129000\n",
      "loss:  0.00392100448\n",
      "training step: 130000\n",
      "loss:  0.00502272369\n",
      "training step: 131000\n",
      "loss:  0.00337483268\n",
      "training step: 132000\n",
      "loss:  0.00375629426\n",
      "training step: 133000\n",
      "loss:  0.00449505588\n",
      "training step: 134000\n",
      "loss:  0.00347085879\n",
      "training step: 135000\n",
      "loss:  0.00408847118\n",
      "training step: 136000\n",
      "loss:  0.00435124617\n",
      "training step: 137000\n",
      "loss:  0.00479196571\n",
      "training step: 138000\n",
      "loss:  0.00350676174\n",
      "training step: 139000\n",
      "loss:  0.0042865579\n",
      "training step: 140000\n",
      "loss:  0.00348163908\n",
      "training step: 141000\n",
      "loss:  0.00332581089\n",
      "training step: 142000\n",
      "loss:  0.00359899318\n",
      "training step: 143000\n",
      "loss:  0.00353245391\n",
      "training step: 144000\n",
      "loss:  0.00323682139\n",
      "training step: 145000\n",
      "loss:  0.00297759962\n",
      "training step: 146000\n",
      "loss:  0.00292727305\n",
      "training step: 147000\n",
      "loss:  0.00291982316\n",
      "training step: 148000\n",
      "loss:  0.00365857058\n",
      "training step: 149000\n",
      "loss:  0.00298911054\n",
      "training step: 150000\n",
      "loss:  0.00355523638\n",
      "training step: 151000\n",
      "loss:  0.00318756839\n",
      "training step: 152000\n",
      "loss:  0.00321460096\n",
      "training step: 153000\n",
      "loss:  0.00286359\n",
      "training step: 154000\n",
      "loss:  0.00313709723\n",
      "training step: 155000\n",
      "loss:  0.00264516426\n",
      "training step: 156000\n",
      "loss:  0.00283400272\n",
      "training step: 157000\n",
      "loss:  0.00317288307\n",
      "training step: 158000\n",
      "loss:  0.00309978472\n",
      "training step: 159000\n",
      "loss:  0.00282598869\n",
      "training step: 160000\n",
      "loss:  0.00305852201\n",
      "training step: 161000\n",
      "loss:  0.00358974794\n",
      "training step: 162000\n",
      "loss:  0.00297880988\n",
      "training step: 163000\n",
      "loss:  0.00344862905\n",
      "training step: 164000\n",
      "loss:  0.00238591293\n",
      "training step: 165000\n",
      "loss:  0.00263573183\n",
      "training step: 166000\n",
      "loss:  0.00251851976\n",
      "training step: 167000\n",
      "loss:  0.00308274082\n",
      "training step: 168000\n",
      "loss:  0.00250468217\n",
      "training step: 169000\n",
      "loss:  0.00274582068\n",
      "training step: 170000\n",
      "loss:  0.00294145849\n",
      "training step: 171000\n",
      "loss:  0.00264572818\n",
      "training step: 172000\n",
      "loss:  0.00272792438\n",
      "training step: 173000\n",
      "loss:  0.00216157362\n",
      "training step: 174000\n",
      "loss:  0.00222613616\n",
      "training step: 175000\n",
      "loss:  0.00238812692\n",
      "training step: 176000\n",
      "loss:  0.00206921832\n",
      "training step: 177000\n",
      "loss:  0.00278658466\n",
      "training step: 178000\n",
      "loss:  0.00253635435\n",
      "training step: 179000\n",
      "loss:  0.00198933482\n",
      "training step: 180000\n",
      "loss:  0.00202492904\n",
      "training step: 181000\n",
      "loss:  0.00210230262\n",
      "training step: 182000\n",
      "loss:  0.00243704021\n",
      "training step: 183000\n",
      "loss:  0.00237705978\n",
      "training step: 184000\n",
      "loss:  0.00220844359\n",
      "training step: 185000\n",
      "loss:  0.00219011726\n",
      "training step: 186000\n",
      "loss:  0.00220167357\n",
      "training step: 187000\n",
      "loss:  0.00179639645\n",
      "training step: 188000\n",
      "loss:  0.00194183632\n",
      "training step: 189000\n",
      "loss:  0.00207126024\n",
      "training step: 190000\n",
      "loss:  0.00198667217\n",
      "training step: 191000\n",
      "loss:  0.00213993504\n",
      "training step: 192000\n",
      "loss:  0.00171063561\n",
      "training step: 193000\n",
      "loss:  0.00220382097\n",
      "training step: 194000\n",
      "loss:  0.00267130369\n",
      "training step: 195000\n",
      "loss:  0.00210605119\n",
      "training step: 196000\n",
      "loss:  0.00158695318\n",
      "training step: 197000\n",
      "loss:  0.00198052963\n",
      "training step: 198000\n",
      "loss:  0.0018526318\n",
      "training step: 199000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 16:27:02.255511: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save2/model/assets\n"
     ]
    }
   ],
   "source": [
    "setting = {'activation':'tanh', 'nn_shape':(256,256,256,256), 'batch_size':1681, 'training_steps':200000,\\\n",
    "'learning_rate': 0.00001, 'decay_rate':0.95, 'decay_per_steps':1000, 'save_step':1000, 'drop_rate':0, 'save_path':'./save2',\\\n",
    "'seed':None, 'debug_traj': True}\n",
    "NN = nn.NN(setting_dict=setting)\n",
    "NN.train(train_mo_pairs,train_c_dexter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0f0bd7-59c4-4f67-85a5-e4229a29dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 4, 41)\n",
    "y = np.linspace(0, 4, 41)\n",
    "Z1 = c_dexter.reshape((41,41))\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.contourf(x,y, np.log(Z1.T))\n",
    "ax.set_title('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3304aa1a-5dda-42e7-8df9-616b116c95af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Error: -0.269%')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.mean(np.multiply(NN.model(train_mo_pairs, training=False).numpy().reshape((1681,))-train_c_dexter, np.power(train_c_dexter,-1))*100)\n",
    "Z = NN.model(train_mo_pairs, training=False).numpy().reshape((41,41))\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.contourf(x,y, np.exp(-Z))\n",
    "ax.set_title('Error: %5.3f%%'%error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087c9dc6-3cbd-4ac4-bfff-1d31338330ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.30743e-01 1.29124e-01 1.24354e-01 ... 4.86700e-03 5.89800e-03\n",
      "  6.57200e-03]\n",
      " [1.29589e-01 1.27982e-01 1.23245e-01 ... 4.88000e-03 5.90300e-03\n",
      "  6.57300e-03]\n",
      " [1.26180e-01 1.24607e-01 1.19977e-01 ... 4.91300e-03 5.91300e-03\n",
      "  6.56500e-03]\n",
      " ...\n",
      " [7.41600e-03 7.31300e-03 7.00300e-03 ... 7.10000e-05 2.68000e-04\n",
      "  4.39000e-04]\n",
      " [6.68000e-03 6.58800e-03 6.31500e-03 ... 1.50000e-05 1.58000e-04\n",
      "  3.11000e-04]\n",
      " [5.96500e-03 5.88500e-03 5.64500e-03 ... 7.90000e-05 7.30000e-05\n",
      "  2.08000e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(Z1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e1af6-287f-4535-9775-a851ad4e6505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
