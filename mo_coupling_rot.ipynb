{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b742ba0e-4145-484e-84e3-293018972888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 02:22:21.032086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-21 02:22:21.032230: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='export TF_INTRA_OP_PARALLELISM_THREADS=12', returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mo_descriptor as md\n",
    "import nn_frame as nn\n",
    "import numpy as np\n",
    "import subprocess\n",
    "subprocess.run('export TF_INTRA_OP_PARALLELISM_THREADS=12', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef29140-72ea-466e-812a-b0d47aa5ff3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. prepare rotated mo\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. prepare rotated mo\n",
    "\n",
    "'''\n",
    "# lumo = md.MO_descriptor('data/lumo-s0.cube').make()\n",
    "# homo = md.MO_descriptor('data/homo-s0.cube').make()\n",
    "# # specify the scanning range\n",
    "# x_rot = np.arange(0.0, 91, 5)\n",
    "# y_rot = np.arange(0.0, 91, 5)\n",
    "# z_rot = np.arange(0.0, 91, 5)\n",
    "\n",
    "# homo_ = np.zeros(homo.shape)\n",
    "# lumo_ = np.zeros(lumo.shape)\n",
    "# homo_[:,0] = homo[:,0]\n",
    "# lumo_[:,0] = lumo[:,0]\n",
    "\n",
    "\n",
    "# homo_pair = md.MO_pair_descriptor(homo, homo).make()\n",
    "# lumo_pair = md.MO_pair_descriptor(lumo, lumo).make()\n",
    "# homo_pairs = np.zeros((len(x_rot)*len(y_rot)*len(z_rot),) + homo_pair.shape)\n",
    "# lumo_pairs = np.zeros((len(x_rot)*len(y_rot)*len(z_rot),) + lumo_pair.shape)\n",
    "\n",
    "# for kk,k in enumerate(z_rot):\n",
    "#     k_ = k / 180 * np.pi\n",
    "#     z_rot_tm = np.array([[np.cos(k_), -np.sin(k_), 0],[np.sin(k_), np.cos(k_), 0], [0,0,1]])\n",
    "#     for ii,i in enumerate(x_rot):\n",
    "#         i_ = i / 180 * np.pi\n",
    "#         x_rot_tm = np.array([[1,0,0], [0, np.cos(i_), -np.sin(i_)],[0, np.sin(i_), np.cos(i_)]])\n",
    "#         for jj,j in enumerate(y_rot):\n",
    "#             j_ = j /180 * np.pi\n",
    "#             idx = kk * len(x_rot) * len(y_rot) + ii * len(y_rot) + jj\n",
    "#             y_rot_tm = np.array([[np.cos(j_), 0, np.sin(j_)],[0,1,0], [-np.sin(j_), 0, np.cos(j_)]])\n",
    "#             homo_[:,1:] = np.einsum('ij,jk,kl,lm->im', homo[:,1:], x_rot_tm, y_rot_tm, z_rot_tm)\n",
    "#             lumo_[:,1:] = np.einsum('ij,jk,kl,lm->im', lumo[:,1:], x_rot_tm, y_rot_tm, z_rot_tm)\n",
    "#             homo_pair = md.MO_pair_descriptor(homo, homo_).make()\n",
    "#             lumo_pair = md.MO_pair_descriptor(lumo, lumo_).make()\n",
    "#             homo_pairs[idx] = homo_pair\n",
    "#             lumo_pairs[idx] = lumo_pair\n",
    "            \n",
    "# np.save('homo_pair_rot.npy', homo_pairs)\n",
    "# np.save('lumo_pair_rot.npy', lumo_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a576414-5c59-4262-8291-f6780550f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_pairs = np.load('homo_pair_rot.npy')\n",
    "lumo_pairs = np.load('lumo_pair_rot.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb19c97-46fc-41de-a1f8-9e7b68985ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. read coupling\n",
    "'''\n",
    "raw_data = np.loadtxt('../ML_Coupling/results_rot.csv', delimiter=',',comments='#')\n",
    "c_homo = abs(raw_data[:,3])\n",
    "c_lumo = abs(raw_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8117c8e4-9838-402a-bb70-bb7fe86544ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3. preprocess data\n",
    "'''\n",
    "izero = []\n",
    "for ii,i in enumerate(c_homo):\n",
    "    if i<=0.0000:\n",
    "        izero.append(ii)\n",
    "        c_homo[ii] = 1e-9\n",
    "print(len(izero))\n",
    "homo_pairs = np.delete(homo_pairs, izero, 0)\n",
    "c_homo = np.delete(c_homo, izero, 0)\n",
    "\n",
    "izero = []\n",
    "for ii,i in enumerate(c_lumo):\n",
    "    if i<=0.0000:\n",
    "        izero.append(ii)\n",
    "        c_lumo[ii] = 1e-8\n",
    "print(len(izero))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7da2450-6145-42cb-ba93-84f4da0364cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_homo_pairs = homo_pairs[:]\n",
    "train_lumo_pairs = lumo_pairs\n",
    "\n",
    "train_c_homo = -np.log(c_homo)[:]\n",
    "train_c_lumo = -np.log(c_lumo)\n",
    "\n",
    "test_homo_pairs = homo_pairs\n",
    "test_lumo_pairs = lumo_pairs\n",
    "\n",
    "test_c_homo = c_homo\n",
    "test_c_lumo = c_lumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cdacadc-531f-4da4-99d1-8ebdf12180ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6737\n",
      "6731\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "train_homo = copy.deepcopy(train_homo_pairs)\n",
    "train_chomo = copy.deepcopy(train_c_homo)\n",
    "print(len(train_chomo))\n",
    "index = np.random.choice(len(train_c_homo), size=int(len(train_c_homo)*0.001), replace=False)\n",
    "train_homo_ = np.delete(train_homo,index,0)\n",
    "train_chomo_ = np.delete(train_chomo,index,0)\n",
    "print(len(train_homo_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dd949bc-5cdb-442b-99de-509dfe958748",
   "metadata": {},
   "outputs": [],
   "source": [
    "iall = np.arange(len(train_c_homo))\n",
    "idiff = np.setdiff1d(iall,index)\n",
    "test_homo = np.delete(copy.deepcopy(train_homo_pairs),idiff,0)\n",
    "test_chomo = np.delete(copy.deepcopy(train_chomo),idiff,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c04257e3-6c81-4e88-aa87-6f86ca86813a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  10.897006\n",
      "training step:     0\n",
      "loss:  0.375492483\n",
      "training step:  1000\n",
      "loss:  0.167069554\n",
      "training step:  2000\n",
      "loss:  0.0499563515\n",
      "training step:  3000\n",
      "loss:  0.0201567356\n",
      "training step:  4000\n",
      "loss:  0.00863359682\n",
      "training step:  5000\n",
      "loss:  0.00408071419\n",
      "training step:  6000\n",
      "loss:  0.00398171786\n",
      "training step:  7000\n",
      "loss:  0.00240018382\n",
      "training step:  8000\n",
      "loss:  0.00104411878\n",
      "training step:  9000\n",
      "loss:  0.0008552043\n",
      "training step: 10000\n",
      "loss:  0.00297786389\n",
      "training step: 11000\n",
      "loss:  0.00102450419\n",
      "training step: 12000\n",
      "loss:  0.000536196923\n",
      "training step: 13000\n",
      "loss:  0.000432663917\n",
      "training step: 14000\n",
      "loss:  0.000366340217\n",
      "training step: 15000\n",
      "loss:  0.000319870072\n",
      "training step: 16000\n",
      "loss:  0.0005457027\n",
      "training step: 17000\n",
      "loss:  0.00170464534\n",
      "training step: 18000\n",
      "loss:  0.000237742352\n",
      "training step: 19000\n",
      "loss:  0.000227767974\n",
      "training step: 20000\n",
      "loss:  0.000339968246\n",
      "training step: 21000\n",
      "loss:  0.000233388142\n",
      "training step: 22000\n",
      "loss:  0.000197930349\n",
      "training step: 23000\n",
      "loss:  0.000242661903\n",
      "training step: 24000\n",
      "loss:  0.000829665107\n",
      "training step: 25000\n",
      "loss:  0.000702519435\n",
      "training step: 26000\n",
      "loss:  0.000467445469\n",
      "training step: 27000\n",
      "loss:  0.000425959937\n",
      "training step: 28000\n",
      "loss:  0.000350829301\n",
      "training step: 29000\n",
      "loss:  0.000109759108\n",
      "training step: 30000\n",
      "loss:  0.000153864137\n",
      "training step: 31000\n",
      "loss:  9.7923e-05\n",
      "training step: 32000\n",
      "loss:  9.93177382e-05\n",
      "training step: 33000\n",
      "loss:  9.98747055e-05\n",
      "training step: 34000\n",
      "loss:  9.88655447e-05\n",
      "training step: 35000\n",
      "loss:  7.53600834e-05\n",
      "training step: 36000\n",
      "loss:  0.000189905477\n",
      "training step: 37000\n",
      "loss:  8.02372597e-05\n",
      "training step: 38000\n",
      "loss:  6.14509117e-05\n",
      "training step: 39000\n",
      "loss:  0.000186015153\n",
      "training step: 40000\n",
      "loss:  0.000105737403\n",
      "training step: 41000\n",
      "loss:  5.00918104e-05\n",
      "training step: 42000\n",
      "loss:  9.45178617e-05\n",
      "training step: 43000\n",
      "loss:  0.000493523432\n",
      "training step: 44000\n",
      "loss:  0.000102199112\n",
      "training step: 45000\n",
      "loss:  0.000100063851\n",
      "training step: 46000\n",
      "loss:  0.0001990772\n",
      "training step: 47000\n",
      "loss:  4.14333044e-05\n",
      "training step: 48000\n",
      "loss:  5.28523633e-05\n",
      "training step: 49000\n",
      "loss:  3.7755548e-05\n",
      "training step: 50000\n",
      "loss:  4.69404949e-05\n",
      "training step: 51000\n",
      "loss:  0.000239749235\n",
      "training step: 52000\n",
      "loss:  4.12407098e-05\n",
      "training step: 53000\n",
      "loss:  0.000181416646\n",
      "training step: 54000\n",
      "loss:  8.53250749e-05\n",
      "training step: 55000\n",
      "loss:  3.96970245e-05\n",
      "training step: 56000\n",
      "loss:  9.0777874e-05\n",
      "training step: 57000\n",
      "loss:  0.000111787442\n",
      "training step: 58000\n",
      "loss:  0.000101478487\n",
      "training step: 59000\n",
      "loss:  3.45963381e-05\n",
      "training step: 60000\n",
      "loss:  2.66897787e-05\n",
      "training step: 61000\n",
      "loss:  2.82438978e-05\n",
      "training step: 62000\n",
      "loss:  0.000191651241\n",
      "training step: 63000\n",
      "loss:  4.18341515e-05\n",
      "training step: 64000\n",
      "loss:  8.46160256e-05\n",
      "training step: 65000\n",
      "loss:  0.000141979646\n",
      "training step: 66000\n",
      "loss:  3.65507221e-05\n",
      "training step: 67000\n",
      "loss:  2.52624886e-05\n",
      "training step: 68000\n",
      "loss:  2.16868502e-05\n",
      "training step: 69000\n",
      "loss:  4.17369447e-05\n",
      "training step: 70000\n",
      "loss:  6.66428386e-05\n",
      "training step: 71000\n",
      "loss:  0.000120850811\n",
      "training step: 72000\n",
      "loss:  0.000359356403\n",
      "training step: 73000\n",
      "loss:  2.71583922e-05\n",
      "training step: 74000\n",
      "loss:  1.60220825e-05\n",
      "training step: 75000\n",
      "loss:  5.95468227e-05\n",
      "training step: 76000\n",
      "loss:  6.70711815e-05\n",
      "training step: 77000\n",
      "loss:  1.50392389e-05\n",
      "training step: 78000\n",
      "loss:  1.46786479e-05\n",
      "training step: 79000\n",
      "loss:  0.000173595734\n",
      "training step: 80000\n",
      "loss:  5.23549934e-05\n",
      "training step: 81000\n",
      "loss:  1.38643118e-05\n",
      "training step: 82000\n",
      "loss:  5.8740985e-05\n",
      "training step: 83000\n",
      "loss:  6.39517311e-05\n",
      "training step: 84000\n",
      "loss:  1.71113461e-05\n",
      "training step: 85000\n",
      "loss:  3.36067678e-05\n",
      "training step: 86000\n",
      "loss:  1.16071024e-05\n",
      "training step: 87000\n",
      "loss:  4.31470507e-05\n",
      "training step: 88000\n",
      "loss:  3.19885403e-05\n",
      "training step: 89000\n",
      "loss:  6.69943693e-05\n",
      "training step: 90000\n",
      "loss:  1.10721767e-05\n",
      "training step: 91000\n",
      "loss:  0.000230623235\n",
      "training step: 92000\n",
      "loss:  2.49435652e-05\n",
      "training step: 93000\n",
      "loss:  9.98248743e-06\n",
      "training step: 94000\n",
      "loss:  0.000102276746\n",
      "training step: 95000\n",
      "loss:  2.29247689e-05\n",
      "training step: 96000\n",
      "loss:  0.000982232741\n",
      "training step: 97000\n",
      "loss:  9.71316622e-05\n",
      "training step: 98000\n",
      "loss:  0.000169618172\n",
      "training step: 99000\n",
      "loss:  0.00018227892\n",
      "training step: 100000\n",
      "loss:  1.21370886e-05\n",
      "training step: 101000\n",
      "loss:  3.81797727e-05\n",
      "training step: 102000\n",
      "loss:  1.74664674e-05\n",
      "training step: 103000\n",
      "loss:  3.78874829e-05\n",
      "training step: 104000\n",
      "loss:  1.053901e-05\n",
      "training step: 105000\n",
      "loss:  1.50298247e-05\n",
      "training step: 106000\n",
      "loss:  0.00024415736\n",
      "training step: 107000\n",
      "loss:  1.11687659e-05\n",
      "training step: 108000\n",
      "loss:  4.65615631e-05\n",
      "training step: 109000\n",
      "loss:  0.000272884383\n",
      "training step: 110000\n",
      "loss:  1.67890903e-05\n",
      "training step: 111000\n",
      "loss:  9.65229447e-06\n",
      "training step: 112000\n",
      "loss:  2.47521657e-05\n",
      "training step: 113000\n",
      "loss:  5.12232764e-05\n",
      "training step: 114000\n",
      "loss:  2.08593701e-05\n",
      "training step: 115000\n",
      "loss:  4.84605262e-05\n",
      "training step: 116000\n",
      "loss:  8.94472e-06\n",
      "training step: 117000\n",
      "loss:  1.19922533e-05\n",
      "training step: 118000\n",
      "loss:  2.35017542e-05\n",
      "training step: 119000\n",
      "loss:  3.78045333e-05\n",
      "training step: 120000\n",
      "loss:  0.000273109821\n",
      "training step: 121000\n",
      "loss:  0.000138040457\n",
      "training step: 122000\n",
      "loss:  1.07387477e-05\n",
      "training step: 123000\n",
      "loss:  5.00753595e-05\n",
      "training step: 124000\n",
      "loss:  5.19701971e-05\n",
      "training step: 125000\n",
      "loss:  0.000114669099\n",
      "training step: 126000\n",
      "loss:  6.18605554e-06\n",
      "training step: 127000\n",
      "loss:  2.44978273e-05\n",
      "training step: 128000\n",
      "loss:  5.28462224e-05\n",
      "training step: 129000\n",
      "loss:  5.47874661e-05\n",
      "training step: 130000\n",
      "loss:  2.98504146e-05\n",
      "training step: 131000\n",
      "loss:  1.01427713e-05\n",
      "training step: 132000\n",
      "loss:  0.000191050029\n",
      "training step: 133000\n",
      "loss:  5.8704295e-06\n",
      "training step: 134000\n",
      "loss:  4.53182802e-05\n",
      "training step: 135000\n",
      "loss:  5.16276523e-05\n",
      "training step: 136000\n",
      "loss:  4.9565665e-06\n",
      "training step: 137000\n",
      "loss:  2.28028166e-05\n",
      "training step: 138000\n",
      "loss:  9.12626e-06\n",
      "training step: 139000\n",
      "loss:  6.25993489e-05\n",
      "training step: 140000\n",
      "loss:  1.1501671e-05\n",
      "training step: 141000\n",
      "loss:  2.75792281e-05\n",
      "training step: 142000\n",
      "loss:  3.97873227e-05\n",
      "training step: 143000\n",
      "loss:  2.3107501e-05\n",
      "training step: 144000\n",
      "loss:  7.52570622e-06\n",
      "training step: 145000\n",
      "loss:  0.000136894028\n",
      "training step: 146000\n",
      "loss:  4.37062317e-06\n",
      "training step: 147000\n",
      "loss:  9.48797606e-06\n",
      "training step: 148000\n",
      "loss:  1.85927456e-05\n",
      "training step: 149000\n",
      "loss:  7.90757258e-05\n",
      "training step: 150000\n",
      "loss:  3.91180038e-06\n",
      "training step: 151000\n",
      "loss:  4.27324921e-05\n",
      "training step: 152000\n",
      "loss:  4.11807059e-06\n",
      "training step: 153000\n",
      "loss:  1.07416163e-05\n",
      "training step: 154000\n",
      "loss:  5.96294703e-05\n",
      "training step: 155000\n",
      "loss:  9.97594634e-06\n",
      "training step: 156000\n",
      "loss:  5.6378185e-06\n",
      "training step: 157000\n",
      "loss:  4.51808273e-06\n",
      "training step: 158000\n",
      "loss:  4.14954666e-05\n",
      "training step: 159000\n",
      "loss:  6.75716146e-05\n",
      "training step: 160000\n",
      "loss:  8.98411454e-05\n",
      "training step: 161000\n",
      "loss:  2.36399956e-05\n",
      "training step: 162000\n",
      "loss:  5.83612418e-05\n",
      "training step: 163000\n",
      "loss:  1.37375e-05\n",
      "training step: 164000\n",
      "loss:  4.05563924e-06\n",
      "training step: 165000\n",
      "loss:  0.000225043463\n",
      "training step: 166000\n",
      "loss:  6.0036622e-05\n",
      "training step: 167000\n",
      "loss:  9.81288395e-06\n",
      "training step: 168000\n",
      "loss:  1.76851172e-05\n",
      "training step: 169000\n",
      "loss:  3.31609335e-05\n",
      "training step: 170000\n",
      "loss:  4.34091744e-05\n",
      "training step: 171000\n",
      "loss:  2.3951834e-05\n",
      "training step: 172000\n",
      "loss:  2.5735053e-05\n",
      "training step: 173000\n",
      "loss:  5.61617162e-05\n",
      "training step: 174000\n",
      "loss:  0.00324644987\n",
      "training step: 175000\n",
      "loss:  3.10085452e-05\n",
      "training step: 176000\n",
      "loss:  1.97445879e-05\n",
      "training step: 177000\n",
      "loss:  6.34769e-05\n",
      "training step: 178000\n",
      "loss:  7.57912348e-05\n",
      "training step: 179000\n",
      "loss:  0.000100747544\n",
      "training step: 180000\n",
      "loss:  5.6329467e-05\n",
      "training step: 181000\n",
      "loss:  2.7353115e-05\n",
      "training step: 182000\n",
      "loss:  0.000168452112\n",
      "training step: 183000\n",
      "loss:  8.69966698e-06\n",
      "training step: 184000\n",
      "loss:  1.20480872e-05\n",
      "training step: 185000\n",
      "loss:  1.63508339e-05\n",
      "training step: 186000\n",
      "loss:  2.04915341e-05\n",
      "training step: 187000\n",
      "loss:  1.85684112e-05\n",
      "training step: 188000\n",
      "loss:  1.77098627e-05\n",
      "training step: 189000\n",
      "loss:  2.77251947e-05\n",
      "training step: 190000\n",
      "loss:  8.18956869e-06\n",
      "training step: 191000\n",
      "loss:  5.61009347e-06\n",
      "training step: 192000\n",
      "loss:  9.50764e-06\n",
      "training step: 193000\n",
      "loss:  7.10181484e-05\n",
      "training step: 194000\n",
      "loss:  1.20780342e-05\n",
      "training step: 195000\n",
      "loss:  3.91749654e-06\n",
      "training step: 196000\n",
      "loss:  1.75687528e-05\n",
      "training step: 197000\n",
      "loss:  3.08323142e-05\n",
      "training step: 198000\n",
      "loss:  7.94297e-06\n",
      "training step: 199000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as flatten_layer_call_fn, flatten_layer_call_and_return_conditional_losses, flatten_1_layer_call_fn, flatten_1_layer_call_and_return_conditional_losses, concatenate_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./nat_dimer_rot_6731/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./nat_dimer_rot_6731/model/assets\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "4. load model\n",
    "'''\n",
    "setting = {'activation':'tanh', 'nn_shape':(256,256,256), 'batch_size':len(train_homo_), 'training_steps':200000,\\\n",
    "'learning_rate': 0.00008, 'decay_rate':0.95, 'decay_per_steps':1000, 'save_step':1000, 'drop_rate':0, 'save_path':'./nat_dimer_rot_%d'%len(train_homo_),\\\n",
    "'seed':None, 'debug_traj':False, 'pre_trained_path':'./nat_dimer_33884/'}\n",
    "NN = nn.NN(setting_dict=setting)\n",
    "NN.train(train_homo_,train_chomo_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aee23c06-e543-4560-8b55-fbe04c66d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of full data set: 0.355 % \n",
      "Error of training set with 6731 samples: 0.355 % \n",
      "Error of testing set with 6 samples: 0.214 % \n"
     ]
    }
   ],
   "source": [
    "error1 = np.mean(np.multiply(abs(NN.model(train_homo_pairs, training=False).numpy().reshape((len(train_homo_pairs),))-train_c_homo), np.power(train_c_homo,-1))*100)\n",
    "error2 = np.mean(np.multiply(abs(NN.model(train_homo_, training=False).numpy().reshape((len(train_homo_),))-train_chomo_), np.power(train_chomo_,-1))*100)\n",
    "error3 = np.mean(np.multiply(abs(NN.model(test_homo, training=False).numpy().reshape((len(test_homo),))-test_chomo), np.power(test_chomo,-1))*100)\n",
    "print('Error of full data set: %5.3f %% \\nError of training set with %d samples: %5.3f %% \\nError of testing set with %d samples: %5.3f %% '%(error1,len(train_homo_),error2,len(test_homo),error3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d809e-8be3-4cb1-a8c2-4c1ce034b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. train the rotation data with pretrained model\n",
    "'''\n",
    "NN(train_homo_pairs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1adeb6ea-422e-4bab-91d4-88242e5c4791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plotting\n",
    "pred1 = NN.model(train_homo_pairs, training=False).numpy().reshape((len(train_homo_pairs),))\n",
    "x = np.exp(-pred1) * 27.211\n",
    "y1 = np.exp(-train_c_homo) * 27.211\n",
    "y2 = train_c_lumo\n",
    "x0 = [0,1.25]\n",
    "y0 = [0,1.25]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y1)\n",
    "ax.plot(x0,y0, color='r')\n",
    "ax.set_xlim(0,0.4)\n",
    "ax.set_ylim(0,0.4)\n",
    "ax.set_xlabel('NN Electron Coupling (eV)')\n",
    "ax.set_ylabel('CDFT Electron Coupling (eV)')\n",
    "ax.set_title('Error: %5.3f%%'%error1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28738194-11d0-4ed2-8bc4-209aaebf6a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
