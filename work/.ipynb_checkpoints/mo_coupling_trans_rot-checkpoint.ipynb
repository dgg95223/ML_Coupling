{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e374ea-67ce-4536-80b8-b3c4bac58c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 17:10:28.285903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-18 17:10:28.286062: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='export TF_INTRA_OP_PARALLELISM_THREADS=12', returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mo_descriptor as md\n",
    "import nn_frame as nn\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import copy\n",
    "subprocess.run('export TF_INTRA_OP_PARALLELISM_THREADS=12', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43b11cb-1fbe-45fa-9086-788654317874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/work/ML_MO_COUPLE\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/homo_homo_pair.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1220/3895239012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhomo_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/homo_homo_pair.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlumo_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/lumo_lumo_pair.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhomo_rot_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/homo_pair_rot.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/homo_homo_pair.npy'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. load mo_pair descriptor\n",
    "'''\n",
    "subprocess.run('pwd',shell=True)\n",
    "homo_pairs = np.load('../data/homo_homo_pair.npy')\n",
    "lumo_pairs = np.load('../data/lumo_lumo_pair.npy')\n",
    "homo_rot_pairs = np.load('../data/homo_pair_rot.npy')\n",
    "lumo_rot_pairs = np.load('../data/lumo_pair_rot.npy')\n",
    "\n",
    "homo_pairs_tr = np.concatenate((homo_pairs,homo_rot_pairs))\n",
    "lumo_pairs_tr = np.concatenate((lumo_pairs,lumo_rot_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812fa84-0a93-4129-a03e-41f895132998",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. read coupling\n",
    "'''\n",
    "raw_data = np.loadtxt('./data/results.csv', delimiter=',',comments='#')\n",
    "raw_data_rot = np.loadtxt('./data/results_rot.csv', delimiter=',',comments='#')\n",
    "c_homo = abs(raw_data[:,3])\n",
    "c_lumo = abs(raw_data[:,4])\n",
    "c_homo_rot = abs(raw_data[:,3])\n",
    "c_lumo_rot = abs(raw_data[:,4])\n",
    "\n",
    "c_homo_tr = np.concatenate((c_homo,c_homo_rot))\n",
    "c_lumo_tr = np.concatenate((c_lumo,c_lumo_rot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ea47a-6f1d-4fc7-93f4-02aecf43d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. remove zero values\n",
    "'''\n",
    "izero = []\n",
    "for ii,i in enumerate(c_homo):\n",
    "    if i<=0.0000:\n",
    "        izero.append(ii)\n",
    "        c_homo[ii] = 1e-9\n",
    "print('Number of points tobe deleted for homo:  ',len(izero))\n",
    "homo_pairs = np.delete(homo_pairs, izero, 0)\n",
    "c_homo = np.delete(c_homo, izero, 0)\n",
    "\n",
    "izero = []\n",
    "for ii,i in enumerate(c_lumo):\n",
    "    if i<=0.0000:\n",
    "        izero.append(ii)\n",
    "        c_lumo[ii] = 1e-8\n",
    "print('Number of points tobe deleted for lumo:  ',len(izero))\n",
    "lumo_pairs = np.delete(lumo_pairs, izero, 0)\n",
    "c_lumo = np.delete(c_lumo, izero, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe46cbe-a7e0-4ee4-8212-a5035b8c9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. build training set\n",
    "'''\n",
    "train_homo_pairs = homo_pairs_tr[:]\n",
    "train_lumo_pairs = lumo_pairs_tr[:]\n",
    "\n",
    "train_c_homo = -np.log(c_homo)[:]\n",
    "train_c_lumo = -np.log(c_lumo)[:]\n",
    "\n",
    "train_homo = copy.deepcopy(train_homo_pairs)\n",
    "train_chomo = copy.deepcopy(train_c_homo)\n",
    "print('Size of full training set for homo:   ',len(train_chomo))\n",
    "index = np.random.choice(len(train_c_homo), size=int(len(train_c_homo)*0.1), replace=False)\n",
    "train_homo_ = np.delete(train_homo,index,0)\n",
    "train_chomo_ = np.delete(train_chomo,index,0)\n",
    "print('Size of selected training set for homo:   ',len(train_homo_))\n",
    "\n",
    "train_lumo = copy.deepcopy(train_lumo_pairs)\n",
    "train_clumo = copy.deepcopy(train_c_lumo)\n",
    "print('Size of full training set for lumo:   ',len(train_clumo))\n",
    "index = np.random.choice(len(train_c_lumo), size=int(len(train_c_lumo)*0.1), replace=False)\n",
    "train_lumo_ = np.delete(train_lumo,index,0)\n",
    "train_clumo_ = np.delete(train_clumo,index,0)\n",
    "print('Size of selected training set for lumo:   ',len(train_lumo_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d41e2-f434-4747-bea5-65e31a00ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. build testing set\n",
    "'''\n",
    "iall = np.arange(len(train_c_homo))\n",
    "idiff = np.setdiff1d(iall,index)\n",
    "test_homo = np.delete(copy.deepcopy(train_homo_pairs),idiff,0)\n",
    "test_chomo = np.delete(copy.deepcopy(train_chomo),idiff,0)\n",
    "\n",
    "iall = np.arange(len(train_c_lumo))\n",
    "idiff = np.setdiff1d(iall,index)\n",
    "test_lumo = np.delete(copy.deepcopy(train_lumo_pairs),idiff,0)\n",
    "test_clumo = np.delete(copy.deepcopy(train_clumo),idiff,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146b4c-306c-46f8-9a27-d2b91ed2b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "6. load model \n",
    "''' \n",
    "setting = {'activation':'tanh','nn_shape':(256,256,256),'batch_size':len(train_homo_), 'training_steps':200000,\\\n",
    "'learning_rate': 0.00008, 'decay_rate':0.95, 'decay_per_steps':1000, 'save_step':1000, 'drop_rate':0, 'save_path':'./nat_dimer_total_%d'%len(train_homo_),\\\n",
    "'seed':None, 'debug_traj':False, 'pre_trained_path':'./nat_dimer_33884/'}\n",
    "NN_ho = nn.NN(setting_dict=setting)\n",
    "NN_ho.train(train_homo_,train_chomo_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbcc8a-a6fd-49b5-9ee9-429c29c9150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = {'activation':'tanh','nn_shape':(256,256,256),'batch_size':len(train_lumo_), 'training_steps':200000,\\\n",
    "'learning_rate': 0.00008, 'decay_rate':0.95, 'decay_per_steps':1000, 'save_step':1000, 'drop_rate':0, 'save_path':'./nat_dimer_total_%d'%len(train_lumo_),\\\n",
    "'seed':None, 'debug_traj':False, 'pre_trained_path':'./nat_dimer_33884/'}\n",
    "NN_lu = nn.NN(setting_dict=setting)\n",
    "NN_lu.train(train_lumo_,train_clumo_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b979eb3-b086-4ce3-b8f4-5f1c27e8bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "error1 = np.mean(np.multiply(abs(NN.model(train_homo_pairs, training=False).numpy().reshape((len(train_homo_pairs),))-train_c_homo), np.power(train_c_homo,-1))*100)\n",
    "error2 = np.mean(np.multiply(abs(NN.model(train_homo_, training=False).numpy().reshape((len(train_homo_),))-train_chomo_), np.power(train_chomo_,-1))*100)\n",
    "error3 = np.mean(np.multiply(abs(NN.model(test_homo, training=False).numpy().reshape((len(test_homo),))-test_chomo), np.power(test_chomo,-1))*100)\n",
    "print('Error of full data set: %5.3f %% \\nError of training set with %d samples: %5.3f %% \\nError of testing set with %d samples: %5.3f %% '\\\n",
    "      %(error1,len(train_homo_),error2,len(test_homo),error3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc930c-bbd4-46c6-a9b8-87f381863665",
   "metadata": {},
   "outputs": [],
   "source": [
    "error1 = np.mean(np.multiply(abs(NN.model(train_lumo_pairs, training=False).numpy().reshape((len(train_lumo_pairs),))-train_c_lumo), np.power(train_c_lumo,-1))*100)\n",
    "error2 = np.mean(np.multiply(abs(NN.model(train_lumo_, training=False).numpy().reshape((len(train_lumo_),))-train_clumo_), np.power(train_clumo_,-1))*100)\n",
    "error3 = np.mean(np.multiply(abs(NN.model(test_lumo, training=False).numpy().reshape((len(test_lumo),))-test_clumo), np.power(test_clumo,-1))*100)\n",
    "print('Error of full data set: %5.3f %% \\nError of training set with %d samples: %5.3f %% \\nError of testing set with %d samples: %5.3f %% '\\\n",
    "      %(error1,len(train_lumo_),error2,len(test_lumo),error3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
