{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308307b8-4561-470e-9de8-9945aa98df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:14:22.604955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-30 17:14:22.605001: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import mo_descriptor as md\n",
    "import nn_frame as nn\n",
    "import numpy as np\n",
    "import subprocess\n",
    "# subprocess.run('export TF_INTRA_OP_PARALLELISM_THREADS=12', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8166d3-a125-4e64-b77b-185abcdc7daa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-4, 4, 81)\n",
    "y = np.linspace(-4, 4, 81)\n",
    "train_y = np.log(np.outer(np.exp(np.square(x)), np.exp(-np.square(y))))\n",
    "train_x = []\n",
    "for ii, i in np.ndenumerate(train_y):\n",
    "    idx = ii[0] * 81 + ii[1]\n",
    "    train_x.append((np.array(ii)-40)*0.1)\n",
    "train_x = np.array(train_x)\n",
    "train_y = train_y.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac96c68-4689-41b3-8270-a8a8fbca0865",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step:     0\n",
      "loss 24547578\n",
      "training step:  1000\n",
      "loss 507607424\n",
      "training step:  2000\n",
      "loss 144909008\n",
      "training step:  3000\n",
      "loss 402270400\n",
      "training step:  4000\n",
      "loss 2.1882e+08\n",
      "training step:  5000\n",
      "loss 223493776\n",
      "training step:  6000\n",
      "loss 156209504\n",
      "training step:  7000\n",
      "loss 90453688\n",
      "training step:  8000\n",
      "loss 105237112\n",
      "training step:  9000\n",
      "loss 105066360\n",
      "training step: 10000\n",
      "loss 63651088\n",
      "training step: 11000\n",
      "loss 62055192\n",
      "training step: 12000\n",
      "loss 34323888\n",
      "training step: 13000\n",
      "loss 31354124\n",
      "training step: 14000\n",
      "loss 33852220\n",
      "training step: 15000\n",
      "loss 41261392\n",
      "training step: 16000\n",
      "loss 29273284\n",
      "training step: 17000\n",
      "loss 23055586\n",
      "training step: 18000\n",
      "loss 44944948\n",
      "training step: 19000\n",
      "loss 42193604\n",
      "training step: 20000\n",
      "loss 28203064\n",
      "training step: 21000\n",
      "loss 19584278\n",
      "training step: 22000\n",
      "loss 38086220\n",
      "training step: 23000\n",
      "loss 38246784\n",
      "training step: 24000\n",
      "loss 20994692\n",
      "training step: 25000\n",
      "loss 12140190\n",
      "training step: 26000\n",
      "loss 16863794\n",
      "training step: 27000\n",
      "loss 25175526\n",
      "training step: 28000\n",
      "loss 14057517\n",
      "training step: 29000\n",
      "loss 19928824\n",
      "training step: 30000\n",
      "loss 26883446\n",
      "training step: 31000\n",
      "loss 21350722\n",
      "training step: 32000\n",
      "loss 6558551.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9272/4096645992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m 'seed':None, 'debug_traj': True}\n\u001b[1;32m      4\u001b[0m \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ML_Coupling/nn_frame.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mistep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# one epoch finished so refresh the data set to start a new epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML_Coupling/nn_frame.py\u001b[0m in \u001b[0;36mbuild_data_set\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# load data from np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, batch_size, drop_remainder, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   1712\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1713\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1714\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mBatchDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m       return ParallelBatchDataset(\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, batch_size, drop_remainder, name)\u001b[0m\n\u001b[1;32m   4895\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4896\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4897\u001b[0;31m     variant_tensor = gen_dataset_ops.batch_dataset_v2(\n\u001b[0m\u001b[1;32m   4898\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4899\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mbatch_dataset_v2\u001b[0;34m(input_dataset, batch_size, drop_remainder, output_types, output_shapes, parallel_copy, metadata, name)\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BatchDatasetV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parallel_copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "setting = {'activation':'tanh', 'nn_shape':(240, 240, 240), 'batch_size':240, 'training_steps':500000,\\\n",
    "'learning_rate': 0.1, 'decay_rate':0.95, 'decay_per_steps':1000, 'save_step':1000, 'drop_rate':0, 'save_path':'./save2/model',\\\n",
    "'seed':None, 'debug_traj': True}\n",
    "NN = nn.NN(setting_dict=setting)\n",
    "NN.train(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b9623-554e-4ccc-9f51-8a661f23a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "x = np.linspace(-4, 4, 81)\n",
    "y = np.linspace(-4, 4, 81)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.log(np.outer(np.exp(np.square(x)), np.exp(-np.square(y))))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.contourf(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcaa214-d31f-431c-a239-8c0ace40caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83970ce7-a323-44cf-b7b9-f822bb4a36b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
