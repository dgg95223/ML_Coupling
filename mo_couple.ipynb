{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65900bf3-c182-48a6-b6a0-efd08e340f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 17:14:19.848802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-15 17:14:19.848848: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='export TF_INTRA_OP_PARALLELISM_THREADS=12', returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mo_descriptor as md\n",
    "import nn_frame as nn\n",
    "import numpy as np\n",
    "import subprocess\n",
    "subprocess.run('export TF_INTRA_OP_PARALLELISM_THREADS=12', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3819da32-6769-405e-8d3f-1fa9c336c9b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "prepare data_set\n",
    "1. make mo_pair descriptor\n",
    "'''\n",
    "# x_shift = np.arange(0, 4.1, 0.1)\n",
    "# y_shift = np.arange(0, 4.1, 0.1)\n",
    "# z_shift = np.zeros(x_shift.shape)\n",
    "# # the original mo, e.g. homo\n",
    "# homo = md.MO_descriptor('data/homo-s0.cube').make()\n",
    "# lumo = md.MO_descriptor('data/lumo-s0.cube').make()\n",
    "\n",
    "# # for the original pair of one mo and itself\n",
    "# homo_pair = md.MO_pair_descriptor(homo, homo).make()\n",
    "# lumo_pair = md.MO_pair_descriptor(lumo, lumo).make()\n",
    "\n",
    "# homo_pairs = np.zeros((len(x_shift)*len(y_shift),) + homo_pair.shape)\n",
    "# lumo_pairs = np.zeros((len(x_shift)*len(y_shift),) + lumo_pair.shape)\n",
    "\n",
    "# homo_ = np.zeros(homo.shape)\n",
    "# lumo_ = np.zeros(lumo.shape)\n",
    "\n",
    "# for ii, i in enumerate(x_shift):\n",
    "#     for jj, j in enumerate(y_shift):\n",
    "#         idx = ii * len(y_shift) + jj\n",
    "#         homo_[:,0] = np.add(homo[:,0],0)\n",
    "#         homo_[:,1] = np.add(homo[:,1],i)\n",
    "#         homo_[:,2] = np.add(homo[:,2],j)\n",
    "#         homo_[:,3] = np.add(homo[:,3],0)\n",
    "        \n",
    "#         homo_pair_ = md.MO_pair_descriptor(homo, homo_).make()\n",
    "#         homo_pairs[idx] = homo_pair_\n",
    "        \n",
    "#         lumo_[:,0] = np.add(lumo[:,0],0)\n",
    "#         lumo_[:,1] = np.add(lumo[:,1],i)\n",
    "#         lumo_[:,2] = np.add(lumo[:,2],j)\n",
    "#         lumo_[:,3] = np.add(lumo[:,3],0)\n",
    "        \n",
    "#         lumo_pair_ = md.MO_pair_descriptor(lumo, lumo_).make()\n",
    "#         lumo_pairs[idx] = lumo_pair_\n",
    "\n",
    "        \n",
    "# def dir_mat(mat):\n",
    "#     mat_shape = mat.shape\n",
    "#     mat_ = mat.flatten()\n",
    "#     for ii, i in enumerate(mat_):\n",
    "#         if i > 1e-6:\n",
    "#             mat_[ii] = 1\n",
    "#         elif (i < 1e-6) and (i > -1e-6):\n",
    "#             mat_[ii] = -1\n",
    "#         elif i < -1e-6:\n",
    "#             mat_[ii] = -1\n",
    "#     return mat_.reshape(mat_shape)\n",
    "\n",
    "# direct = dir_mat(homo_pair)\n",
    "\n",
    "# # for the shifted pair\n",
    "# homo_pairs = np.zeros((len(x_shift)*len(y_shift),) + homo_pair.shape)\n",
    "# lumo_pairs = np.zeros((len(x_shift)*len(y_shift),) + lumo_pair.shape)\n",
    "# for ii, i in enumerate(x_shift):\n",
    "#     for jj, j in enumerate(y_shift):\n",
    "#         idx = ii * len(y_shift) + jj\n",
    "#         homo_pairs[idx][0] = homo_pair[0]\n",
    "#         homo_pairs[idx][1] = np.add(homo_pair[1],i*direct[1])\n",
    "#         homo_pairs[idx][2] = np.add(homo_pair[2],j*direct[2])\n",
    "#         homo_pairs[idx][3] = homo_pair[3]\n",
    "#         lumo_pairs[idx][0] = lumo_pair[0]\n",
    "#         lumo_pairs[idx][1] = np.add(lumo_pair[1],i)\n",
    "#         lumo_pairs[idx][2] = np.add(lumo_pair[2],j)\n",
    "#         lumo_pairs[idx][3] = lumo_pair[3]\n",
    "# np.save('homo_homo_pair.npy', homo_pairs)\n",
    "# np.save('lumo_lumo_pair.npy', lumo_pairs)\n",
    "homo_pairs = np.load('homo_homo_pair.npy')\n",
    "lumo_pairs = np.load('lumo_lumo_pair.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91a92a2-f076-46c8-835f-958569393703",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. read coupling\n",
    "'''\n",
    "raw_data = np.loadtxt('data/cdft-V1V2.dat')\n",
    "c_homo = np.add(raw_data[:,2], raw_data[:,3]) * 1/2\n",
    "c_lumo = np.add(raw_data[:,4], raw_data[:,5]) * 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda7ef17-1e21-42a4-9daf-27feba4fc51b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x1 = homo_pairs[:,0,:,:]\n",
    "# x2 = homo_pairs[:,1,:,:]\n",
    "# x3 = homo_pairs[:,2,:,:]\n",
    "# x4 = homo_pairs[:,3,:,:]\n",
    "# x = np.einsum('aij,aij,aij,aij->aij', x1, x2, x3, x4)\n",
    "\n",
    "train_homo_pairs = homo_pairs\n",
    "train_lumo_pairs = lumo_pairs\n",
    "\n",
    "train_c_homo = -np.log(c_homo)\n",
    "train_c_lumo = -np.log(c_lumo)\n",
    "\n",
    "test_homo_pairs = homo_pairs[1200:]\n",
    "test_lumo_pairs = lumo_pairs[1200:]\n",
    "\n",
    "test_c_homo = c_homo[1200:].reshape((len(c_homo[1200:]),1))\n",
    "test_c_lumo = c_lumo[1200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d30ba-e044-469f-b2eb-25f05497f346",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 17:14:21.666783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-15 17:14:21.666838: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-15 17:14:21.666872: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Bai-Group): /proc/driver/nvidia/version does not exist\n",
      "2022-09-15 17:14:21.667368: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  10.2643414\n",
      "training step:     0\n",
      "loss:  7.53479624\n",
      "training step:  1000\n",
      "loss:  7.34343863\n",
      "training step:  2000\n",
      "loss:  7.20050192\n",
      "training step:  3000\n",
      "loss:  7.06335068\n",
      "training step:  4000\n",
      "loss:  6.92652273\n",
      "training step:  5000\n",
      "loss:  6.79195452\n",
      "training step:  6000\n",
      "loss:  6.65731\n",
      "training step:  7000\n",
      "loss:  6.52165\n",
      "training step:  8000\n",
      "loss:  6.38582182\n",
      "training step:  9000\n",
      "loss:  6.25015926\n",
      "training step: 10000\n",
      "loss:  6.1143055\n",
      "training step: 11000\n",
      "loss:  5.97842503\n",
      "training step: 12000\n",
      "loss:  5.84259701\n",
      "training step: 13000\n",
      "loss:  5.7067914\n",
      "training step: 14000\n",
      "loss:  5.57095861\n",
      "training step: 15000\n",
      "loss:  5.4350729\n",
      "training step: 16000\n",
      "loss:  5.29913187\n",
      "training step: 17000\n",
      "loss:  5.16316032\n",
      "training step: 18000\n",
      "loss:  5.02712345\n",
      "training step: 19000\n",
      "loss:  4.89104\n",
      "training step: 20000\n",
      "loss:  4.75496912\n",
      "training step: 21000\n",
      "loss:  4.61903334\n",
      "training step: 22000\n",
      "loss:  4.48326206\n",
      "training step: 23000\n",
      "loss:  4.34763098\n",
      "training step: 24000\n",
      "loss:  4.2121892\n",
      "training step: 25000\n",
      "loss:  4.07707596\n",
      "training step: 26000\n",
      "loss:  3.94235086\n",
      "training step: 27000\n",
      "loss:  3.80815601\n",
      "training step: 28000\n",
      "loss:  3.67453241\n",
      "training step: 29000\n",
      "loss:  3.54159832\n",
      "training step: 30000\n",
      "loss:  3.40942478\n",
      "training step: 31000\n",
      "loss:  3.2780714\n",
      "training step: 32000\n",
      "loss:  3.14763498\n",
      "training step: 33000\n",
      "loss:  3.01824188\n",
      "training step: 34000\n",
      "loss:  2.89006042\n",
      "training step: 35000\n",
      "loss:  2.76313806\n",
      "training step: 36000\n",
      "loss:  2.63767219\n",
      "training step: 37000\n",
      "loss:  2.51366305\n",
      "training step: 38000\n",
      "loss:  2.39124846\n",
      "training step: 39000\n",
      "loss:  2.27056336\n",
      "training step: 40000\n",
      "loss:  2.15165019\n",
      "training step: 41000\n",
      "loss:  2.03460312\n",
      "training step: 42000\n",
      "loss:  1.91957974\n",
      "training step: 43000\n",
      "loss:  1.80675316\n",
      "training step: 44000\n",
      "loss:  1.69617534\n",
      "training step: 45000\n",
      "loss:  1.58811092\n",
      "training step: 46000\n",
      "loss:  1.48259759\n",
      "training step: 47000\n",
      "loss:  1.37972403\n",
      "training step: 48000\n",
      "loss:  1.27961946\n",
      "training step: 49000\n",
      "loss:  1.18234205\n",
      "training step: 50000\n",
      "loss:  1.08808136\n",
      "training step: 51000\n",
      "loss:  0.996955574\n",
      "training step: 52000\n",
      "loss:  0.909217656\n",
      "training step: 53000\n",
      "loss:  0.824875057\n",
      "training step: 54000\n",
      "loss:  0.744019568\n",
      "training step: 55000\n",
      "loss:  0.666753\n",
      "training step: 56000\n",
      "loss:  0.593271732\n",
      "training step: 57000\n",
      "loss:  0.523751736\n",
      "training step: 58000\n",
      "loss:  0.458182752\n",
      "training step: 59000\n",
      "loss:  0.396693885\n",
      "training step: 60000\n",
      "loss:  0.339502931\n",
      "training step: 61000\n",
      "loss:  0.286571205\n",
      "training step: 62000\n",
      "loss:  0.238105297\n",
      "training step: 63000\n",
      "loss:  0.194108739\n",
      "training step: 64000\n",
      "loss:  0.154717654\n",
      "training step: 65000\n",
      "loss:  0.119958267\n",
      "training step: 66000\n",
      "loss:  0.0898634493\n",
      "training step: 67000\n",
      "loss:  0.0644448772\n",
      "training step: 68000\n",
      "loss:  0.0436508246\n",
      "training step: 69000\n",
      "loss:  0.0273821019\n",
      "training step: 70000\n",
      "loss:  0.0154354451\n",
      "training step: 71000\n",
      "loss:  0.00746190641\n",
      "training step: 72000\n",
      "loss:  0.00290107192\n",
      "training step: 73000\n",
      "loss:  0.000898117141\n",
      "training step: 74000\n",
      "loss:  0.000347001973\n",
      "training step: 75000\n",
      "loss:  0.000269803568\n",
      "training step: 76000\n",
      "loss:  0.000260916451\n",
      "training step: 77000\n",
      "loss:  0.000239244124\n",
      "training step: 78000\n",
      "loss:  0.000226274118\n",
      "training step: 79000\n",
      "loss:  0.00021338262\n",
      "training step: 80000\n",
      "loss:  0.000202896219\n",
      "training step: 81000\n",
      "loss:  0.000194390755\n",
      "training step: 82000\n",
      "loss:  0.000186435063\n",
      "training step: 83000\n",
      "loss:  0.000177510257\n",
      "training step: 84000\n",
      "loss:  0.000236952386\n",
      "training step: 85000\n",
      "loss:  0.000162349141\n",
      "training step: 86000\n",
      "loss:  0.000155948335\n",
      "training step: 87000\n",
      "loss:  0.00014947381\n",
      "training step: 88000\n",
      "loss:  0.00014390258\n",
      "training step: 89000\n",
      "loss:  0.000138538366\n",
      "training step: 90000\n",
      "loss:  0.000133204667\n",
      "training step: 91000\n",
      "loss:  0.000128434302\n",
      "training step: 92000\n",
      "loss:  0.000123223741\n",
      "training step: 93000\n",
      "loss:  0.000119167809\n",
      "training step: 94000\n",
      "loss:  0.000115043207\n",
      "training step: 95000\n",
      "loss:  0.000111217436\n",
      "training step: 96000\n",
      "loss:  0.000107978805\n",
      "training step: 97000\n",
      "loss:  0.000104211984\n",
      "training step: 98000\n",
      "loss:  0.000101090576\n",
      "training step: 99000\n",
      "loss:  9.82084675e-05\n",
      "training step: 100000\n",
      "loss:  9.52118862e-05\n",
      "training step: 101000\n",
      "loss:  9.25341956e-05\n",
      "training step: 102000\n",
      "loss:  8.96503552e-05\n",
      "training step: 103000\n",
      "loss:  8.72307428e-05\n",
      "training step: 104000\n",
      "loss:  8.47623814e-05\n",
      "training step: 105000\n",
      "loss:  8.27048207e-05\n",
      "training step: 106000\n",
      "loss:  8.06002718e-05\n",
      "training step: 107000\n",
      "loss:  7.83540308e-05\n",
      "training step: 108000\n",
      "loss:  7.64642609e-05\n",
      "training step: 109000\n",
      "loss:  7.44847202e-05\n",
      "training step: 110000\n",
      "loss:  7.25992941e-05\n",
      "training step: 111000\n",
      "loss:  7.09484739e-05\n",
      "training step: 112000\n",
      "loss:  6.92039466e-05\n",
      "training step: 113000\n",
      "loss:  6.728484e-05\n",
      "training step: 114000\n",
      "loss:  6.5943168e-05\n",
      "training step: 115000\n",
      "loss:  6.45388864e-05\n",
      "training step: 116000\n",
      "loss:  6.28442576e-05\n",
      "training step: 117000\n",
      "loss:  6.1607112e-05\n",
      "training step: 118000\n",
      "loss:  6.03616172e-05\n",
      "training step: 119000\n",
      "loss:  5.89978044e-05\n",
      "training step: 120000\n",
      "loss:  5.77555256e-05\n",
      "training step: 121000\n",
      "loss:  5.66732197e-05\n",
      "training step: 122000\n",
      "loss:  5.56068881e-05\n",
      "training step: 123000\n",
      "loss:  5.43072274e-05\n",
      "training step: 124000\n",
      "loss:  5.33815073e-05\n",
      "training step: 125000\n",
      "loss:  5.24353527e-05\n",
      "training step: 126000\n",
      "loss:  5.14126732e-05\n",
      "training step: 127000\n",
      "loss:  5.04401469e-05\n",
      "training step: 128000\n",
      "loss:  4.94801861e-05\n",
      "training step: 129000\n",
      "loss:  4.8501046e-05\n",
      "training step: 130000\n",
      "loss:  4.77545946e-05\n",
      "training step: 131000\n",
      "loss:  4.68609687e-05\n",
      "training step: 132000\n",
      "loss:  4.60799602e-05\n",
      "training step: 133000\n",
      "loss:  4.5193643e-05\n",
      "training step: 134000\n",
      "loss:  4.43393183e-05\n",
      "training step: 135000\n",
      "loss:  4.37389754e-05\n",
      "training step: 136000\n",
      "loss:  4.28882049e-05\n",
      "training step: 137000\n",
      "loss:  4.20421056e-05\n",
      "training step: 138000\n",
      "loss:  4.14137758e-05\n",
      "training step: 139000\n",
      "loss:  4.07291955e-05\n",
      "training step: 140000\n",
      "loss:  4.00612262e-05\n",
      "training step: 141000\n",
      "loss:  3.95026364e-05\n",
      "training step: 142000\n",
      "loss:  3.87539476e-05\n",
      "training step: 143000\n",
      "loss:  3.8139242e-05\n",
      "training step: 144000\n",
      "loss:  3.75936361e-05\n",
      "training step: 145000\n",
      "loss:  0.00010965985\n",
      "training step: 146000\n",
      "loss:  3.62431711e-05\n",
      "training step: 147000\n",
      "loss:  3.57399913e-05\n",
      "training step: 148000\n",
      "loss:  3.51411654e-05\n",
      "training step: 149000\n",
      "loss:  3.45363696e-05\n",
      "training step: 150000\n",
      "loss:  3.40002807e-05\n",
      "training step: 151000\n",
      "loss:  3.35393124e-05\n",
      "training step: 152000\n",
      "loss:  3.28673596e-05\n",
      "training step: 153000\n",
      "loss:  3.23584682e-05\n",
      "training step: 154000\n",
      "loss:  3.197552e-05\n",
      "training step: 155000\n",
      "loss:  3.14285717e-05\n",
      "training step: 156000\n",
      "loss:  3.09774259e-05\n",
      "training step: 157000\n",
      "loss:  3.05338799e-05\n",
      "training step: 158000\n",
      "loss:  3.00919419e-05\n",
      "training step: 159000\n",
      "loss:  2.96183753e-05\n",
      "training step: 160000\n",
      "loss:  3.05089434e-05\n",
      "training step: 161000\n",
      "loss:  2.87768489e-05\n",
      "training step: 162000\n",
      "loss:  2.82584788e-05\n",
      "training step: 163000\n",
      "loss:  2.78407188e-05\n",
      "training step: 164000\n",
      "loss:  2.74595295e-05\n",
      "training step: 165000\n",
      "loss:  2.705929e-05\n",
      "training step: 166000\n",
      "loss:  2.66267598e-05\n",
      "training step: 167000\n",
      "loss:  0.000172952248\n",
      "training step: 168000\n",
      "loss:  2.59267836e-05\n",
      "training step: 169000\n",
      "loss:  2.54516399e-05\n",
      "training step: 170000\n",
      "loss:  2.51154306e-05\n",
      "training step: 171000\n",
      "loss:  2.47774842e-05\n",
      "training step: 172000\n",
      "loss:  2.44083531e-05\n",
      "training step: 173000\n",
      "loss:  2.39942419e-05\n",
      "training step: 174000\n",
      "loss:  2.35894277e-05\n",
      "training step: 175000\n",
      "loss:  2.33386818e-05\n",
      "training step: 176000\n",
      "loss:  2.31759623e-05\n",
      "training step: 177000\n",
      "loss:  2.26515531e-05\n",
      "training step: 178000\n",
      "loss:  2.23062962e-05\n",
      "training step: 179000\n",
      "loss:  2.19967769e-05\n",
      "training step: 180000\n",
      "loss:  2.17064753e-05\n",
      "training step: 181000\n",
      "loss:  2.14064148e-05\n",
      "training step: 182000\n",
      "loss:  2.11101924e-05\n",
      "training step: 183000\n",
      "loss:  2.0817999e-05\n",
      "training step: 184000\n",
      "loss:  2.05453143e-05\n",
      "training step: 185000\n",
      "loss:  2.02732608e-05\n",
      "training step: 186000\n",
      "loss:  1.99852711e-05\n",
      "training step: 187000\n",
      "loss:  1.96940709e-05\n",
      "training step: 188000\n",
      "loss:  1.94243657e-05\n",
      "training step: 189000\n",
      "loss:  1.91885829e-05\n",
      "training step: 190000\n",
      "loss:  1.89402017e-05\n",
      "training step: 191000\n",
      "loss:  1.87171881e-05\n",
      "training step: 192000\n",
      "loss:  1.84170676e-05\n",
      "training step: 193000\n",
      "loss:  1.8195793e-05\n",
      "training step: 194000\n",
      "loss:  1.79742638e-05\n",
      "training step: 195000\n",
      "loss:  1.76579397e-05\n",
      "training step: 196000\n",
      "loss:  1.74655088e-05\n",
      "training step: 197000\n"
     ]
    }
   ],
   "source": [
    "setting = {'activation':'tanh', 'nn_shape':(256,256,256), 'batch_size':1681, 'training_steps':200000,\\\n",
    "'learning_rate': 0.000001, 'decay_rate':0.95, 'decay_per_steps':1000, 'save_step':1000, 'drop_rate':0, 'save_path':'./save',\\\n",
    "'seed':None, 'debug_traj': False}\n",
    "NN = nn.NN(setting_dict=setting)\n",
    "NN.train(train_homo_pairs,train_c_homo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143ab74-322f-4b26-9ee5-7f7d433b2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "error = np.mean(np.multiply(NN.model(train_homo_pairs, training=False).numpy().reshape((1681,))-train_c_homo, np.power(train_c_homo,-1))*100)\n",
    "x = np.linspace(0, 4, 41)\n",
    "y = np.linspace(0, 4, 41)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = NN.model(train_homo_pairs, training=False).numpy().reshape((41,41)).T\n",
    "Z1 = c_homo.reshape((41,41)).T\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.contourf(x,y, np.exp(-Z))\n",
    "ax.set_title('Error: %5.3f%%'%error)\n",
    "ax.set_aspect('equal')\n",
    "plt.savefig('homo_pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeac264-1b61-4a8a-bb30-b368f5551f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ace6c2-030a-4f0d-aef2-2440da10b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = NN.model(train_homo_pairs, training=False).numpy().reshape((1681,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400e85d-e7ae-41eb-b40a-45a708342731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8b103-0aa4-4c38-a408-14dce3dd6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.multiply(a-train_c_homo, np.power(train_c_homo,-1)))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790e593-9420-43a7-8f9c-514740afee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.contourf(x,y, Z1)\n",
    "ax.set_title('True')\n",
    "ax.set_aspect('equal')\n",
    "plt.savefig('homo_true.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357bcee0-c41f-4b8d-be9b-2225ec9f7b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
